{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Betotzy/FaceReco-Using-GNet-by-CV-Kelompok-C/blob/main/FaceReco_Project_GoogleNet_Inception_V3_Prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "14m9CuMSV_d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.models import inception_v3\n",
        "from torchvision.models import vgg16\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "amicBIpHV-1W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "exSWLJtJWDba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RDo8QRgZXbub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506ca3b2-5380-4c2a-90f9-d91ce85c2201"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yCge1a3I_Tls"
      },
      "outputs": [],
      "source": [
        "data_path='/content/drive/MyDrive/FaceReco/Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn9Lmi5m_cQM",
        "outputId": "60de3200-8bb1-40ae-db95-86fa730315e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['class_identity.txt',\n",
              " 'gender_classification.csv',\n",
              " 'list_attribute.txt',\n",
              " 'gender_classification.xlsx',\n",
              " 'Images',\n",
              " 'Images_clean']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_list = os.listdir(data_path+'/Images')"
      ],
      "metadata": {
        "id": "bZGqLTQHNpzv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca file list_attribute.txt yang berisi informasi atribut gambar. Merapikan data dengan separasi spasi dan skip kolom metadata\n",
        "data = pd.read_csv(data_path+'/list_attribute.txt', sep='\\s+', skiprows=1)\n",
        "\n",
        "# images_list berisi nama file 5000 gambar yang benar-benar ada.\n",
        "# Kode ini menyaring agar hanya atribut gambar tersebut yang diambil.\n",
        "filtered_data = data[data.index.isin(images_list)]\n",
        "\n",
        "# Hanya kolom 'Male' yang diambil dari dataset. reset_index() mengubah nama gambar dari index menjadi kolom biasa.\n",
        "filtered_data = filtered_data[['Male']].reset_index()\n",
        "\n",
        "# Kolom yang berisi nama gambar diubah namanya menjadi image_id agar lebih jelas.\n",
        "filtered_data = filtered_data.rename(columns={'index': 'image_id'})\n",
        "\n",
        "# Awalnya data 'Male' berisi 1 (laki-laki) dan -1 (bukan laki-laki). Diubah menjadi 1 (laki-laki) dan 0 (bukan laki-laki) supaya cocok untuk model machine learning.\n",
        "filtered_data['Male'] = filtered_data['Male'].apply(lambda x: 1 if x == 1 else 0)\n",
        "\n",
        "# Buat variabel filtered_data dengan data\n",
        "data = filtered_data\n",
        "\n",
        "print(data.head())\n",
        "print(data.shape)\n",
        "print(\"Unique values in 'Male' column after conversion:\", data['Male'].unique())"
      ],
      "metadata": {
        "id": "iT0VLH-D_j8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3dd12f-eecf-42ab-feab-95ad503158d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-3120962094.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  data = pd.read_csv(data_path+'/list_attribute.txt', sep='\\s+', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     image_id  Male\n",
            "0  000051.jpg     1\n",
            "1  000052.jpg     1\n",
            "2  000352.jpg     1\n",
            "3  000409.jpg     1\n",
            "4  000545.jpg     1\n",
            "(1768, 2)\n",
            "Unique values in 'Male' column after conversion: [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test sets with a 80:20 ratio\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wqq-6PUZdGRO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "vlqeTieFWUTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenderDataset(Dataset):\n",
        "    def __init__(self, data, image_folder_path, transform=None):\n",
        "        self.data = data\n",
        "        self.image_folder_path = image_folder_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_folder_path, self.data.iloc[idx, 0])\n",
        "        image = Image.open(image_path).convert('RGB') # convert image to RGB\n",
        "        gender = self.data.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(gender, dtype=torch.long)"
      ],
      "metadata": {
        "id": "4OqB-qUm_nfm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),           # resize ke 299x299 (ukuran input Inception V3)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # augmentasi: flipping kiri/kanan\n",
        "    transforms.ColorJitter(                  # augmentasi: variasi warna/kontras\n",
        "        brightness=0.2,\n",
        "        contrast=0.2,\n",
        "        saturation=0.2,\n",
        "        hue=0.1\n",
        "    ),\n",
        "\n",
        "    transforms.ToTensor(),                   # ubah ke tensor [0,1]\n",
        "    transforms.Normalize(                    # normalisasi pakai mean & std ImageNet\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "wPVfdZZV_pFs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = GenderDataset(train_data, image_folder_path=os.path.join(data_path, \"Images\"), transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "test_set = GenderDataset(test_data, os.path.join(data_path, \"Images\"), transform=transform)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "X73R5VKe_qeM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture"
      ],
      "metadata": {
        "id": "TWLDlYSVWWyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please define the model optimizer and criterion (loss function)\n",
        "model = inception_v3(pretrained=True, aux_logits=True)\n",
        "# Modifikasi layer terakhir untuk tugas classification (2 classes: Male/Female)\n",
        "# Inception V3 mempunyai struktur layer terakhir yang berbeda, seperti Linear layer yang diikuti oleh AuxLogits layer (sebagai layer bantuan agar model stabil).\n",
        "# Kita modifikasi Linear Layer dan AuxLogits Layernya.\n",
        "num_ftrs = model.fc.in_features\n",
        "# Tambahkan dropout layer pada classification layer terakhir untuk meminimalisir overfitting\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.5),  # atur nilai dropout sebesar 0.5\n",
        "    nn.Linear(num_ftrs, 2)\n",
        ")\n",
        "\n",
        "# Modifikasi AuxLogits Layer\n",
        "num_aux_ftrs = model.AuxLogits.fc.in_features\n",
        "model.AuxLogits.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3), # tambahkan dropout layer dan atur nilai dropout sebesar 0.3\n",
        "    nn.Linear(num_aux_ftrs, 2)\n",
        ")\n",
        "\n",
        "# Define optimizer and criterion\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5) #Gunakan optimizer Adam agar model lebih konvergen, gunakan juga weight decay agar weight/ bobot tidak terlalu besar\n",
        "criterion = nn.CrossEntropyLoss() #CrossEntropyLoss untuk multiclass classification"
      ],
      "metadata": {
        "id": "jUuOH-ra_r5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cab4787-dc92-4916-fb12-f9958dde07b6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "abgEJucmWyp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu=torch.cuda.is_available(), num_epochs=10, patience=5, min_delta=0.001):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) # buat copy / model cadangan\n",
        "    best_acc = 0.0 # Set akurasi terbaik mulai dari 0\n",
        "\n",
        "    train_acc_history = []\n",
        "    test_acc_history = []\n",
        "\n",
        "    epochs_no_improve = 0 # Variabel epochs_no_improve dipakai untuk menghitung berapa kali berturut-turut akurasi test/validasi tidak membaik. Training berhenti otomatis ketika sudah jelas tidak ada perbaikan, hal ini dapat meminimalisir overfitting\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and evaluation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)  # Set model to training mode\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            # alat ukur yang bikin kita bisa tahu apakah overfitting terjadi.\n",
        "\n",
        "            # Iterate over data.\n",
        "            for data in dataloaders[phase]:\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "\n",
        "                # wrap them in Variable\n",
        "                if use_gpu: # Gunakan GPU jika ada (agar proses training lebih cepat)\n",
        "                    inputs = Variable(inputs.cuda())\n",
        "                    labels = Variable(labels.cuda())\n",
        "                else: # Jika tidak ada GPU, gunakan CPU (lebih lambat dari GPU)\n",
        "                    inputs = Variable(inputs)\n",
        "                    labels = Variable(labels)\n",
        "                    # Jika training berjalan lambat, ada potensi training berhenti di tengah jalan, hal ini akan menyebabkan model underfitting\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad() # mengosongkan gradien lama sebelum hitung gradien baru.\n",
        "                # Jika tiap batch dilakukan zero_grad, Model akan update bobot dengan informasi yang jernih, sehingga akurasi train & test lebih stabil.\n",
        "\n",
        "                # forward\n",
        "                if phase == 'train':\n",
        "                    # Inception V3 hanya mengeluarkan 2 output yaitu output dari main classifier dan output dari auxillaries classifier\n",
        "                    outputs, aux_outputs = model(inputs)\n",
        "                    loss1 = criterion(outputs, labels) # loss dari main classifier\n",
        "                    loss2 = criterion(aux_outputs, labels) # loss dari auxillaries classifier\n",
        "                    loss = loss1 + 0.4 * loss2 # auxillaries hanya diberi 40 % dari nilai lossnya karena hanya sebagai jalur bantuan\n",
        "                else:\n",
        "                    # In evaluation mode,hanya output dari main classifier saja yang digunakan\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward() # inti dari deep learning. Tanpa ini, bobot tidak akan pernah belajar dari kesalahan.\n",
        "                    optimizer.step() # kalau ini tidak ada, model akan stuck dengan bobot awal (tidak ada perbaikan).\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.data * inputs.size(0) # Multiply by batch size for correct loss calculation\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] # Convert to double for accurate division\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc.item())\n",
        "            else:\n",
        "                test_acc_history.append(epoch_acc.item())\n",
        "\n",
        "            # deep copy the model if test accuracy improved\n",
        "            if phase == 'test':\n",
        "                if epoch_acc > best_acc + min_delta:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    epochs_no_improve = 0\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    if epochs_no_improve == patience:\n",
        "                        print(\"Early stopping!\")\n",
        "                        time_elapsed = time.time() - since\n",
        "                        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "                            time_elapsed // 60, time_elapsed % 60))\n",
        "                        print('Best test Accuracy: {:4f}'.format(best_acc)) # Corrected print statement\n",
        "                        model.load_state_dict(best_model_wts)\n",
        "                        return model, train_acc_history, test_acc_history\n",
        "\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Accuracy: {:4f}'.format(best_acc)) # Corrected print statement\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_acc_history, test_acc_history"
      ],
      "metadata": {
        "id": "8QN5AiKU_7tI"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloders = {\n",
        "    \"train\":train_loader, \"test\":test_loader\n",
        "}\n",
        "dataset_sizes= {\n",
        "    \"train\":len(train_set), \"test\":len(test_set)\n",
        "}"
      ],
      "metadata": {
        "id": "FA70lw6QAzRp"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "if use_gpu:\n",
        "  # The train_model function returns a tuple, the first element is the model\n",
        "  model = model.to(\"cuda\")\n",
        "else:\n",
        "  model = model"
      ],
      "metadata": {
        "id": "PtYpHMMCA3YR"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, train_acc_history, test_acc_history = train_model(model, dataloders, dataset_sizes, criterion, optimizer, use_gpu, 10)"
      ],
      "metadata": {
        "id": "_yFxAf6JA5pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f5657dc-aabd-4670-c7af-6ce061a0a6f3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.0007 Acc: 1.0000\n",
            "test Loss: 0.1000 Acc: 0.9633\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.0005 Acc: 1.0000\n",
            "test Loss: 0.0765 Acc: 0.9718\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.0010 Acc: 1.0000\n",
            "test Loss: 0.0728 Acc: 0.9661\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0007 Acc: 1.0000\n",
            "test Loss: 0.0848 Acc: 0.9689\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0003 Acc: 1.0000\n",
            "test Loss: 0.1051 Acc: 0.9661\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0040 Acc: 0.9986\n",
            "test Loss: 0.0971 Acc: 0.9718\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0396 Acc: 0.9936\n",
            "test Loss: 0.1053 Acc: 0.9661\n",
            "Early stopping!\n",
            "Training complete in 1m 41s\n",
            "Best test Accuracy: 0.971751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "EXpMpLXGW2_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, target_labels):\n",
        "    # please define the evaluation function here\n",
        "    model.eval() # Set model to evaluate mode\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "        for inputs, labels in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Print classification report\n",
        "    print(classification_report(all_labels, all_preds, target_names=target_labels))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "ujCwmsBgCGir"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, dataloders['test'], [\"female\", \"male\"])"
      ],
      "metadata": {
        "id": "R92ueXtqA7gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410c9182-73e6-4cf5-ebc4-3f2cb682a86c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.99      0.96      0.97       214\n",
            "        male       0.94      0.98      0.96       140\n",
            "\n",
            "    accuracy                           0.97       354\n",
            "   macro avg       0.97      0.97      0.97       354\n",
            "weighted avg       0.97      0.97      0.97       354\n",
            "\n",
            "Confusion Matrix:\n",
            "[[206   8]\n",
            " [  3 137]]\n"
          ]
        }
      ]
    }
  ]
}