{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "14m9CuMSV_d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "amicBIpHV-1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "exSWLJtJWDba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RDo8QRgZXbub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35ecb5c-de98-4a94-f6a3-9855c5fcdaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCge1a3I_Tls"
      },
      "outputs": [],
      "source": [
        "data_path='/content/drive/MyDrive/FaceReco/Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn9Lmi5m_cQM",
        "outputId": "50eae744-f4ba-47b9-dee7-3e4c4a850abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gender_classification.csv',\n",
              " 'class_identity.txt',\n",
              " 'list_attribute.txt',\n",
              " 'gender_classification.xlsx',\n",
              " 'Images']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_list = os.listdir(data_path+'/Images')"
      ],
      "metadata": {
        "id": "bZGqLTQHNpzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca file list_attribute.txt yang berisi informasi atribut gambar. Merapikan data dengan separasi spasi dan skip kolom metadata\n",
        "data = pd.read_csv(data_path+'/list_attribute.txt', sep='\\s+', skiprows=1)\n",
        "\n",
        "# images_list berisi nama file 5000 gambar yang benar-benar ada.\n",
        "# Kode ini menyaring agar hanya atribut gambar tersebut yang diambil.\n",
        "filtered_data = data[data.index.isin(images_list)]\n",
        "\n",
        "# Hanya kolom 'Male' yang diambil dari dataset. reset_index() mengubah nama gambar dari index menjadi kolom biasa.\n",
        "filtered_data = filtered_data[['Male']].reset_index()\n",
        "\n",
        "# Kolom yang berisi nama gambar diubah namanya menjadi image_id agar lebih jelas.\n",
        "filtered_data = filtered_data.rename(columns={'index': 'image_id'})\n",
        "\n",
        "# Awalnya data 'Male' berisi 1 (laki-laki) dan -1 (bukan laki-laki). Diubah menjadi 1 (laki-laki) dan 0 (bukan laki-laki) supaya cocok untuk model machine learning.\n",
        "filtered_data['Male'] = filtered_data['Male'].apply(lambda x: 1 if x == 1 else 0)\n",
        "\n",
        "# Assign the filtered data to the 'data' variable as requested\n",
        "data = filtered_data\n",
        "\n",
        "print(data.head())\n",
        "print(data.shape)\n",
        "print(\"Unique values in 'Male' column after conversion:\", data['Male'].unique())"
      ],
      "metadata": {
        "id": "iT0VLH-D_j8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7eb6a0-01bd-441c-96f9-7767357a6101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-3120962094.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  data = pd.read_csv(data_path+'/list_attribute.txt', sep='\\s+', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     image_id  Male\n",
            "0  000051.jpg     1\n",
            "1  000052.jpg     1\n",
            "2  000352.jpg     1\n",
            "3  000409.jpg     1\n",
            "4  000545.jpg     1\n",
            "(1768, 2)\n",
            "Unique values in 'Male' column after conversion: [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test sets with a 80:20 ratio\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wqq-6PUZdGRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "vlqeTieFWUTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenderDataset(Dataset):\n",
        "    def __init__(self, data, image_folder_path, transform=None):\n",
        "        self.data = data\n",
        "        self.image_folder_path = image_folder_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_folder_path, self.data.iloc[idx, 0])\n",
        "        # please define image convertion technique to RGB here\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        gender = self.data.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(gender, dtype=torch.long)"
      ],
      "metadata": {
        "id": "4OqB-qUm_nfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    # please define data transformation techniques here\n",
        "    transforms.Resize((299, 299)),  # Resize images to a consistent size\n",
        "    transforms.ToTensor(),         # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize image data\n",
        "])"
      ],
      "metadata": {
        "id": "wPVfdZZV_pFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = GenderDataset(train_data, image_folder_path=os.path.join(data_path, \"Images\"), transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "test_set = GenderDataset(test_data, os.path.join(data_path, \"Images\"), transform=transform)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "X73R5VKe_qeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture"
      ],
      "metadata": {
        "id": "TWLDlYSVWWyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please define the model optimizer and criterion (loss function)\n",
        "from torchvision import models\n",
        "from torchvision.models import inception_v3\n",
        "model = inception_v3(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "jUuOH-ra_r5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96d235a-0ed8-4289-d04c-9e81741faff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104M/104M [00:00<00:00, 180MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "abgEJucmWyp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu=torch.cuda.is_available(), num_epochs=10):\n",
        "    # please define the training model (VGG/GoogleNet/ResNet) here\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "    train_acc_history = []\n",
        "    test_acc_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                #scheduler.step()\n",
        "                model.train(True)  # Set model to training mode\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for data in dataloders[phase]:\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "\n",
        "                # wrap them in Variable\n",
        "                if use_gpu:\n",
        "                    inputs = Variable(inputs.cuda())\n",
        "                    labels = Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                if phase == 'train':\n",
        "                    outputs, aux_outputs = model(inputs)\n",
        "                    loss1 = criterion(outputs, labels)\n",
        "                    loss2 = criterion(aux_outputs, labels)\n",
        "                    loss = loss1 + 0.4 * loss2 # Total loss is a weighted sum\n",
        "                    _, preds = torch.max(outputs.data, 1)\n",
        "                else:\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.data\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc.item())\n",
        "            else:\n",
        "                test_acc_history.append(epoch_acc.item())\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "    pass"
      ],
      "metadata": {
        "id": "8QN5AiKU_7tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloders = {\n",
        "    \"train\":train_loader, \"test\":test_loader\n",
        "}\n",
        "dataset_sizes= {\n",
        "    \"train\":len(train_set), \"test\":len(test_set)\n",
        "}"
      ],
      "metadata": {
        "id": "FA70lw6QAzRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "if use_gpu:\n",
        "  model = model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "PtYpHMMCA3YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, dataloders, dataset_sizes, criterion, optimizer, use_gpu, 10)"
      ],
      "metadata": {
        "id": "_yFxAf6JA5pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f5c6f6-0a8c-4b21-b196-6695c9dc6866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.1312 Acc: 0.4873\n",
            "test Loss: 0.0240 Acc: 0.4774\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.1311 Acc: 0.4760\n",
            "test Loss: 0.0241 Acc: 0.4548\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.1312 Acc: 0.4965\n",
            "test Loss: 0.0241 Acc: 0.4576\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.1314 Acc: 0.4745\n",
            "test Loss: 0.0240 Acc: 0.4520\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1315 Acc: 0.4632\n",
            "test Loss: 0.0240 Acc: 0.4605\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1311 Acc: 0.4993\n",
            "test Loss: 0.0242 Acc: 0.4350\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1315 Acc: 0.4646\n",
            "test Loss: 0.0241 Acc: 0.4661\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1311 Acc: 0.5057\n",
            "test Loss: 0.0241 Acc: 0.4661\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1316 Acc: 0.4590\n",
            "test Loss: 0.0241 Acc: 0.4576\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1315 Acc: 0.4894\n",
            "test Loss: 0.0241 Acc: 0.4774\n",
            "\n",
            "Training complete in 2m 1s\n",
            "Best test Acc: 0.477401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "EXpMpLXGW2_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, target_labels):\n",
        "    # please define the evaluation function here\n",
        "    pass"
      ],
      "metadata": {
        "id": "ujCwmsBgCGir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, dataloders['test'], [\"female\", \"male\"])"
      ],
      "metadata": {
        "id": "R92ueXtqA7gA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}